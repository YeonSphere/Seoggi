// Lexer for Seoggi

// This lexer will tokenize the input source code into manageable pieces.

function tokenize(input) {
    const tokensArray = [];
    const regex = /[a-zA-Z_][a-zA-Z0-9_]*|\d+|[=();{}]/g;
    let match;

    while ((match = regex.exec(input)) !== null) {
        let token;
        if (/\d+/.test(match[0])) {
            token = { type: tokens.NUMBER.type, value: match[0], color: tokens.NUMBER.color };
        } else if (/^(if|else|while|for|func)$/.test(match[0])) {
            token = { type: tokens.KEYWORD.type, value: match[0], color: tokens.KEYWORD.color };
        } else {
            token = { type: tokens.IDENTIFIER.type, value: match[0], color: tokens.IDENTIFIER.color };
        }
        tokensArray.push(token);
    }
    return tokensArray;
}

// Define tokens with color codes
const tokens = {
    IDENTIFIER: { type: 'IDENTIFIER', color: '\x1b[32m' }, // Green
    NUMBER: { type: 'NUMBER', color: '\x1b[34m' }, // Blue
    KEYWORD: { type: 'KEYWORD', color: '\x1b[31m' }, // Red
};

// Reset color
const RESET_COLOR = '\x1b[0m';
