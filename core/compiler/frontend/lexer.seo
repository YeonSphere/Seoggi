// Seoggi Lexer Implementation
// Inspired by modern lexer designs from Rust, Swift, and Kotlin

use std::str::Chars;
use std::iter::Peekable;
use std::collections::HashMap;
use crate::error::{Error, ErrorKind, Position};
use crate::token::{Token, TokenType, Literal, TokenMetadata, Attribute, Visibility};

pub struct Lexer<'a> {
    input: Peekable<Chars<'a>>,
    current: Position,
    tokens: Vec<Token>,
    had_error: bool,
    source: &'a str,
    start_offset: usize,
    current_offset: usize,
    indent_stack: Vec<usize>,
    current_indent: usize,
    pending_tokens: Vec<Token>,
    current_metadata: TokenMetadata,
}

impl<'a> Lexer<'a> {
    pub fn new(source: &'a str) -> Self {
        Self {
            input: source.chars().peekable(),
            current: Position::new(1, 1),
            tokens: Vec::new(),
            had_error: false,
            source,
            start_offset: 0,
            current_offset: 0,
            indent_stack: vec![0],
            current_indent: 0,
            pending_tokens: Vec::new(),
            current_metadata: TokenMetadata::default(),
        }
    }
    
    pub fn scan_tokens(&mut self) -> Result<Vec<Token>, Error> {
        while let Some(c) = self.advance() {
            self.start_offset = self.current_offset - 1;
            let token = match c {
                // Single-character tokens
                '(' => self.make_token(TokenType::LeftParen),
                ')' => self.make_token(TokenType::RightParen),
                '{' => self.make_token(TokenType::LeftBrace),
                '}' => self.make_token(TokenType::RightBrace),
                '[' => self.make_token(TokenType::LeftBracket),
                ']' => self.make_token(TokenType::RightBracket),
                ',' => self.make_token(TokenType::Comma),
                ';' => self.make_token(TokenType::Semicolon),
                ':' => self.make_token(TokenType::Colon),
                '?' => self.make_token(TokenType::Question),
                '@' => self.handle_attribute(),
                '#' => self.make_token(TokenType::Hash),
                '$' => self.make_token(TokenType::Dollar),
                
                // One or two character tokens
                '+' => self.match_compound('+', TokenType::PlusPlus, '=', TokenType::PlusEqual, TokenType::Plus),
                '-' => self.handle_minus(),
                '*' => self.match_equals(TokenType::StarEqual, TokenType::Star),
                '/' => self.handle_slash(),
                '%' => self.match_equals(TokenType::PercentEqual, TokenType::Percent),
                '=' => self.handle_equals(),
                '!' => self.handle_bang(),
                '>' => self.handle_greater(),
                '<' => self.handle_less(),
                '&' => self.match_compound('&', TokenType::AmpAmp, '=', TokenType::AmpEqual, TokenType::Amp),
                '|' => self.match_compound('|', TokenType::PipePipe, '=', TokenType::PipeEqual, TokenType::Pipe),
                '^' => self.match_equals(TokenType::CaretEqual, TokenType::Caret),
                '.' => self.handle_dot(),
                
                // String literals
                '"' => self.string(),
                '\'' => self.char_literal(),
                
                // Numbers
                '0'..='9' => self.number(),
                
                // Identifiers and keywords
                'a'..='z' | 'A'..='Z' | '_' => self.identifier(),
                
                // Whitespace and indentation
                ' ' | '\t' => self.handle_indent(),
                '\n' => self.handle_newline(),
                '\r' => continue,
                
                // Invalid characters
                _ => self.error(ErrorKind::UnexpectedCharacter(c)),
            }?;
            
            if token.type_ != TokenType::Whitespace {
                self.tokens.push(token);
            }
        }
        
        // Handle any remaining dedents at EOF
        while self.indent_stack.len() > 1 {
            self.tokens.push(Token::new(
                TokenType::Dedent,
                String::new(),
                None,
                self.current.clone()
            ));
            self.indent_stack.pop();
        }
        
        // Add EOF token
        self.tokens.push(Token::new(
            TokenType::EOF,
            String::new(),
            None,
            self.current.clone()
        ));
        
        if self.had_error {
            Err(Error::new(ErrorKind::LexicalError, self.current.clone()))
        } else {
            Ok(self.tokens.clone())
        }
    }
    
    // New methods for handling additional features
    
    fn handle_attribute(&mut self) -> Result<Token, Error> {
        let start_pos = self.current.clone();
        let mut name = String::new();
        let mut args = Vec::new();
        
        // Skip whitespace after @
        while let Some(c) = self.peek() {
            if !c.is_whitespace() { break; }
            self.advance();
        }
        
        // Parse attribute name
        while let Some(c) = self.peek() {
            if !c.is_ascii_alphanumeric() && c != '_' { break; }
            name.push(self.advance().unwrap());
        }
        
        // Parse attribute arguments if present
        if self.match_char('(') {
            while let Some(c) = self.peek() {
                match c {
                    ')' => {
                        self.advance();
                        break;
                    }
                    ',' => {
                        self.advance();
                        continue;
                    }
                    '"' => {
                        self.advance();
                        let arg = self.string()?;
                        if let Some(Literal::String(s)) = arg.literal {
                            args.push(s);
                        }
                    }
                    _ if c.is_whitespace() => {
                        self.advance();
                    }
                    _ => return self.error(ErrorKind::InvalidAttributeSyntax),
                }
            }
        }
        
        let attr = match name.as_str() {
            "inline" => Attribute::Inline,
            "noinline" => Attribute::NoInline,
            "virtual" => Attribute::Virtual,
            "override" => Attribute::Override,
            "pure" => Attribute::Pure,
            "unsafe" => Attribute::Unsafe,
            "deprecated" => {
                let msg = args.first().cloned().unwrap_or_default();
                Attribute::Deprecated(msg)
            }
            _ => Attribute::Custom(name, args),
        };
        
        Ok(Token::new(
            TokenType::Attribute(attr.clone()),
            format!("@{}", name),
            None,
            start_pos
        ))
    }
    
    fn handle_indent(&mut self) -> Result<Token, Error> {
        if self.current.column == 1 {
            let mut indent = 0;
            while let Some(c) = self.peek() {
                match c {
                    ' ' => indent += 1,
                    '\t' => indent += 8, // Convert tabs to spaces
                    _ => break,
                }
                self.advance();
            }
            
            if indent > self.indent_stack.last().copied().unwrap_or(0) {
                self.indent_stack.push(indent);
                return Ok(Token::new(TokenType::Indent, String::new(), None, self.current.clone()));
            } else if indent < self.indent_stack.last().copied().unwrap_or(0) {
                let mut tokens = Vec::new();
                while indent < self.indent_stack.last().copied().unwrap_or(0) {
                    self.indent_stack.pop();
                    tokens.push(Token::new(TokenType::Dedent, String::new(), None, self.current.clone()));
                }
                if indent != self.indent_stack.last().copied().unwrap_or(0) {
                    return self.error(ErrorKind::InvalidIndentation);
                }
                self.pending_tokens.extend(tokens);
            }
        }
        
        Ok(Token::new(TokenType::Whitespace, String::new(), None, self.current.clone()))
    }
    
    fn handle_newline(&mut self) -> Result<Token, Error> {
        self.current.line += 1;
        self.current.column = 1;
        Ok(Token::new(TokenType::Newline, String::new(), None, self.current.clone()))
    }
    
    fn handle_dot(&mut self) -> Result<Token, Error> {
        if self.match_char('.') {
            if self.match_char('.') {
                Ok(Token::new(TokenType::DotDotDot, String::from("..."), None, self.current.clone()))
            } else {
                self.error(ErrorKind::UnexpectedCharacter('.'))
            }
        } else {
            Ok(Token::new(TokenType::Dot, String::from("."), None, self.current.clone()))
        }
    }
    
    fn handle_minus(&mut self) -> Result<Token, Error> {
        if self.match_char('-') {
            Ok(Token::new(TokenType::MinusMinus, String::from("--"), None, self.current.clone()))
        } else if self.match_char('=') {
            Ok(Token::new(TokenType::MinusEqual, String::from("-="), None, self.current.clone()))
        } else if self.match_char('>') {
            if self.match_char('>') {
                Ok(Token::new(TokenType::FatArrow, String::from("=>"), None, self.current.clone()))
            } else {
                Ok(Token::new(TokenType::Arrow, String::from("->"), None, self.current.clone()))
            }
        } else {
            Ok(Token::new(TokenType::Minus, String::from("-"), None, self.current.clone()))
        }
    }
    
    fn handle_equals(&mut self) -> Result<Token, Error> {
        if self.match_char('=') {
            if self.match_char('=') {
                Ok(Token::new(TokenType::EqualEqualEqual, String::from("==="), None, self.current.clone()))
            } else {
                Ok(Token::new(TokenType::EqualEqual, String::from("=="), None, self.current.clone()))
            }
        } else {
            Ok(Token::new(TokenType::Equal, String::from("="), None, self.current.clone()))
        }
    }
    
    fn handle_bang(&mut self) -> Result<Token, Error> {
        if self.match_char('=') {
            if self.match_char('=') {
                Ok(Token::new(TokenType::BangEqualEqual, String::from("!=="), None, self.current.clone()))
            } else {
                Ok(Token::new(TokenType::BangEqual, String::from("!="), None, self.current.clone()))
            }
        } else {
            Ok(Token::new(TokenType::Bang, String::from("!"), None, self.current.clone()))
        }
    }
    
    // Helper methods for token creation and character handling
    fn make_token(&self, type_: TokenType) -> Result<Token, Error> {
        Ok(Token {
            type_,
            lexeme: String::new(),
            literal: None,
            pos: self.current.clone(),
        })
    }
    
    fn match_equals(&mut self, if_match: TokenType, if_not: TokenType) -> Result<Token, Error> {
        let type_ = if self.match_char('=') { if_match } else { if_not };
        self.make_token(type_)
    }
    
    fn match_compound(&mut self, 
        double: char, double_type: TokenType,
        equals: char, equals_type: TokenType,
        base_type: TokenType) -> Result<Token, Error> {
        if self.match_char(double) {
            self.make_token(double_type)
        } else if self.match_char(equals) {
            self.make_token(equals_type)
        } else {
            self.make_token(base_type)
        }
    }
    
    fn handle_slash(&mut self) -> Result<Token, Error> {
        if self.match_char('/') {
            // Single-line comment
            while let Some(c) = self.peek() {
                if c == '\n' { break; }
                self.advance();
            }
            self.make_token(TokenType::Comment)
        } else if self.match_char('*') {
            // Multi-line comment
            self.multiline_comment()
        } else if self.match_char('=') {
            self.make_token(TokenType::SlashEqual)
        } else {
            self.make_token(TokenType::Slash)
        }
    }
    
    fn handle_greater(&mut self) -> Result<Token, Error> {
        if self.match_char('>') {
            if self.match_char('=') {
                self.make_token(TokenType::RightShiftEqual)
            } else {
                self.make_token(TokenType::RightShift)
            }
        } else if self.match_char('=') {
            self.make_token(TokenType::GreaterEqual)
        } else {
            self.make_token(TokenType::Greater)
        }
    }
    
    fn handle_less(&mut self) -> Result<Token, Error> {
        if self.match_char('<') {
            if self.match_char('=') {
                self.make_token(TokenType::LeftShiftEqual)
            } else {
                self.make_token(TokenType::LeftShift)
            }
        } else if self.match_char('=') {
            self.make_token(TokenType::LessEqual)
        } else {
            self.make_token(TokenType::Less)
        }
    }
    
    // String literal handling
    fn string(&mut self) -> Result<Token, Error> {
        let start_pos = self.current.clone();
        let mut value = String::new();
        
        while let Some(c) = self.peek() {
            if c == '"' {
                self.advance(); // Consume closing quote
                return Ok(Token {
                    type_: TokenType::String,
                    lexeme: value.clone(),
                    literal: Some(Literal::String(value)),
                    pos: start_pos,
                });
            }
            
            if c == '\n' {
                return self.error(ErrorKind::UnterminatedStringLiteral);
            }
            
            if c == '\\' {
                self.advance(); // Consume backslash
                match self.advance() {
                    Some('n') => value.push('\n'),
                    Some('r') => value.push('\r'),
                    Some('t') => value.push('\t'),
                    Some('\\') => value.push('\\'),
                    Some('"') => value.push('"'),
                    Some(c) => return self.error(ErrorKind::InvalidEscapeSequence(c)),
                    None => return self.error(ErrorKind::UnterminatedStringLiteral),
                }
            } else {
                value.push(self.advance().unwrap());
            }
        }
        
        self.error(ErrorKind::UnterminatedStringLiteral)
    }
    
    // Character literal handling
    fn char_literal(&mut self) -> Result<Token, Error> {
        let start_pos = self.current.clone();
        
        let value = match self.advance() {
            Some('\\') => match self.advance() {
                Some('n') => '\n',
                Some('r') => '\r',
                Some('t') => '\t',
                Some('\\') => '\\',
                Some('\'') => '\'',
                Some(c) => return self.error(ErrorKind::InvalidEscapeSequence(c)),
                None => return self.error(ErrorKind::UnterminatedCharacterLiteral),
            },
            Some('\'') => return self.error(ErrorKind::EmptyCharacterLiteral),
            Some(c) => c,
            None => return self.error(ErrorKind::UnterminatedCharacterLiteral),
        };
        
        match self.advance() {
            Some('\'') => Ok(Token {
                type_: TokenType::Char,
                lexeme: value.to_string(),
                literal: Some(Literal::Char(value)),
                pos: start_pos,
            }),
            Some(_) => self.error(ErrorKind::CharacterLiteralContainsMoreThanOneCharacter),
            None => self.error(ErrorKind::UnterminatedCharacterLiteral),
        }
    }
    
    // Number literal handling
    fn number(&mut self) -> Result<Token, Error> {
        let start_pos = self.current.clone();
        let mut value = String::new();
        let mut is_float = false;
        
        // Handle hex, octal, and binary literals
        if self.peek() == Some('x') {
            value.push('0');
            value.push('x');
            self.advance(); // Consume 'x'
            while let Some(c) = self.peek() {
                if !c.is_ascii_hexdigit() { break; }
                value.push(self.advance().unwrap());
            }
            if value.len() <= 2 {
                return self.error(ErrorKind::InvalidHexadecimalNumber);
            }
            let num = i64::from_str_radix(&value[2..], 16)
                .map_err(|_| Error::new(ErrorKind::InvalidHexadecimalNumber))?;
            return Ok(Token {
                type_: TokenType::Int,
                lexeme: value,
                literal: Some(Literal::Int(num)),
                pos: start_pos,
            });
        }
        
        // Parse decimal part
        while let Some(c) = self.peek() {
            if !c.is_ascii_digit() { break; }
            value.push(self.advance().unwrap());
        }
        
        // Handle decimal point
        if self.peek() == Some('.') && self.peek_next().map_or(false, |c| c.is_ascii_digit()) {
            is_float = true;
            value.push(self.advance().unwrap()); // Consume '.'
            
            while let Some(c) = self.peek() {
                if !c.is_ascii_digit() { break; }
                value.push(self.advance().unwrap());
            }
        }
        
        // Handle exponent
        if let Some('e' | 'E') = self.peek() {
            is_float = true;
            value.push(self.advance().unwrap());
            
            if let Some('+' | '-') = self.peek() {
                value.push(self.advance().unwrap());
            }
            
            let mut has_digits = false;
            while let Some(c) = self.peek() {
                if !c.is_ascii_digit() { break; }
                has_digits = true;
                value.push(self.advance().unwrap());
            }
            
            if !has_digits {
                return self.error(ErrorKind::InvalidFloatingPointNumber);
            }
        }
        
        if is_float {
            let num = value.parse::<f64>()
                .map_err(|_| Error::new(ErrorKind::InvalidFloatingPointNumber))?;
            Ok(Token {
                type_: TokenType::Float,
                lexeme: value,
                literal: Some(Literal::Float(num)),
                pos: start_pos,
            })
        } else {
            let num = value.parse::<i64>()
                .map_err(|_| Error::new(ErrorKind::InvalidInteger))?;
            Ok(Token {
                type_: TokenType::Int,
                lexeme: value,
                literal: Some(Literal::Int(num)),
                pos: start_pos,
            })
        }
    }
    
    // Identifier and keyword handling
    fn identifier(&mut self) -> Result<Token, Error> {
        let start_pos = self.current.clone();
        let mut value = String::new();
        
        while let Some(c) = self.peek() {
            if !c.is_ascii_alphanumeric() && c != '_' { break; }
            value.push(self.advance().unwrap());
        }
        
        let type_ = KEYWORDS.get(value.as_str()).cloned().unwrap_or(TokenType::Identifier);
        
        Ok(Token {
            type_,
            lexeme: value,
            literal: None,
            pos: start_pos,
        })
    }
    
    // Whitespace handling
    fn whitespace(&mut self) -> Result<Token, Error> {
        while let Some(c) = self.peek() {
            match c {
                ' ' | '\r' | '\t' => { self.advance(); }
                _ => break,
            }
        }
        self.make_token(TokenType::Whitespace)
    }
    
    // Multi-line comment handling
    fn multiline_comment(&mut self) -> Result<Token, Error> {
        let start_pos = self.current.clone();
        let mut nesting = 1;
        
        while nesting > 0 {
            match self.advance() {
                Some('/') => {
                    if self.match_char('*') {
                        nesting += 1;
                    }
                }
                Some('*') => {
                    if self.match_char('/') {
                        nesting -= 1;
                    }
                }
                Some(_) => {}
                None => return self.error(ErrorKind::UnterminatedMultiLineComment),
            }
        }
        
        Ok(Token {
            type_: TokenType::Comment,
            lexeme: String::new(),
            literal: None,
            pos: start_pos,
        })
    }
    
    // Additional helper method for peeking two characters ahead
    fn peek_next(&mut self) -> Option<char> {
        let mut iter = self.input.clone();
        iter.next(); // Skip current
        iter.next()  // Get next
    }
    
    // Character iteration methods
    fn advance(&mut self) -> Option<char> {
        let c = self.input.next()?;
        self.current.offset += 1;
        self.current.column += 1;
        self.current_offset += 1;
        Some(c)
    }
    
    fn peek(&mut self) -> Option<char> {
        self.input.peek().copied()
    }
    
    fn match_char(&mut self, expected: char) -> bool {
        match self.peek() {
            Some(c) if c == expected => {
                self.advance();
                true
            }
            _ => false,
        }
    }
    
    fn newline(&mut self) -> Result<Token, Error> {
        self.current.line += 1;
        self.current.column = 1;
        self.make_token(TokenType::NewLine)
    }
    
    // Error handling
    fn error(&mut self, kind: ErrorKind) -> Result<Token, Error> {
        self.had_error = true;
        Ok(Token {
            type_: TokenType::Error,
            lexeme: kind.to_string(),
            literal: None,
            pos: self.current.clone(),
        })
    }
}

// Keyword mapping
lazy_static! {
    static ref KEYWORDS: HashMap<&'static str, TokenType> = {
        let mut map = HashMap::new();
        map.insert("module", TokenType::Module);
        map.insert("import", TokenType::Import);
        map.insert("export", TokenType::Export);
        map.insert("use", TokenType::Use);
        map.insert("as", TokenType::As);
        map.insert("class", TokenType::Class);
        map.insert("trait", TokenType::Trait);
        map.insert("interface", TokenType::Interface);
        map.insert("impl", TokenType::Impl);
        map.insert("extends", TokenType::Extends);
        map.insert("implements", TokenType::Implements);
        map.insert("function", TokenType::Function);
        map.insert("constructor", TokenType::Constructor);
        map.insert("let", TokenType::Let);
        map.insert("var", TokenType::Var);
        map.insert("type", TokenType::Type);
        map.insert("effect", TokenType::Effect);
        map.insert("if", TokenType::If);
        map.insert("else", TokenType::Else);
        map.insert("match", TokenType::Match);
        map.insert("while", TokenType::While);
        map.insert("for", TokenType::For);
        map.insert("loop", TokenType::Loop);
        map.insert("in", TokenType::In);
        map.insert("break", TokenType::Break);
        map.insert("continue", TokenType::Continue);
        map.insert("return", TokenType::Return);
        map.insert("yield", TokenType::Yield);
        map.insert("async", TokenType::Async);
        map.insert("await", TokenType::Await);
        map.insert("try", TokenType::Try);
        map.insert("catch", TokenType::Catch);
        map.insert("throw", TokenType::Throw);
        map.insert("finally", TokenType::Finally);
        map.insert("public", TokenType::Public);
        map.insert("private", TokenType::Private);
        map.insert("protected", TokenType::Protected);
        map.insert("internal", TokenType::Internal);
        map.insert("static", TokenType::Static);
        map.insert("final", TokenType::Final);
        map.insert("abstract", TokenType::Abstract);
        map.insert("override", TokenType::Override);
        map.insert("true", TokenType::True);
        map.insert("false", TokenType::False);
        map.insert("null", TokenType::Null);
        map.insert("self", TokenType::Self_);
        map.insert("super", TokenType::Super);
        map.insert("pure", TokenType::Pure);
        map.insert("impure", TokenType::Impure);
        map.insert("effect", TokenType::Effect);
        map.insert("handle", TokenType::Handle);
        map.insert("resume", TokenType::Resume);
        map.insert("pattern", TokenType::Pattern);
        map.insert("when", TokenType::When);
        map.insert("is", TokenType::Is);
        map.insert("as", TokenType::As);
        map.insert("guard", TokenType::Guard);
        map.insert("where", TokenType::Where);
        map.insert("bounded", TokenType::Bounded);
        map.insert("constrained", TokenType::Constrained);
        map.insert("spawn", TokenType::Spawn);
        map.insert("channel", TokenType::Channel);
        map.insert("select", TokenType::Select);
        map.insert("receive", TokenType::Receive);
        map.insert("allocate", TokenType::Allocate);
        map.insert("free", TokenType::Free);
        map.insert("move", TokenType::Move);
        map.insert("copy", TokenType::Copy);
        map.insert("borrow", TokenType::Borrow);
        map
    };
}
