import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

class DataProcessor:
    def __init__(self):
        self.scaler = StandardScaler()

    def load_data(self, file_path):
        # Load data from a file (e.g., CSV)
        data = np.genfromtxt(file_path, delimiter=',')
        return data

    def preprocess(self, data):
        # Split features and target
        X = data[:, :-1]
        y = data[:, -1]

        # Normalize features
        X_scaled = self.scaler.fit_transform(X)

        return X_scaled, y

    def split_data(self, X, y, test_size=0.2, random_state=42):
        # Split data into training and testing sets
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)
        return X_train, X_test, y_train, y_test

    def process_data(self, file_path):
        data = self.load_data(file_path)
        X, y = self.preprocess(data)
        return self.split_data(X, y)

# Example usage
if __name__ == "__main__":
    processor = DataProcessor()
    X_train, X_test, y_train, y_test = processor.process_data("path/to/your/data.csv")
    print("Data processed successfully.")
    print(f"Training set shape: {X_train.shape}")
    print(f"Testing set shape: {X_test.shape}")
